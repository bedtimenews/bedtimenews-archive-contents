---
title: 【产经破壁机083】为什么DeepSeek是大模型的“安卓时刻”？
description: 从“大力出奇迹”的Scaling Law到强化学习，大模型的技术范式和产品应用正在被重新定义。
published: true
date: 2025-03-20T10:02:22.562Z
tags: 
editor: markdown
dateCreated: 2025-03-19T10:45:20.530Z
---

# Tabs {.tabset}

## B站

<div style="position: relative; padding: 30% 45%;">
<iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="//player.bilibili.com/player.html?&bvid=BV1g8QbYqEz3&page=1&as_wide=1&high_quality=1&danmaku=1&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>
</div>


#

> 以下文本为音频转录结果，存在一定错误，校对正在进行中。
{.is-warning}

2024年11月，彭博社在一篇报道中断言OpenAI、谷歌和Anthropic等巨头已经在训练更先进的AI模型上陷入困境。他们为构建新模型付出努力，但带来的回报却正在减少，以至于频繁推迟发布新产品。OpenAI的CEO Sam Altman在X上发布了这份宣言，隔空回击彭博社，“你不了解AI，但妄下断言”。

虽然Altman相信人工智能训练的收益递减并不存在，规模效应没有收敛，OpenAI坚信的“大力出奇迹”还没有到撞墙的时候。但是三个月后，最终拿出惊艳全球的推理模型的并不是OpenAI，而是DeepSeek。

这股“AI训练大模型陷入瓶颈”的焦虑早在2024年9月就已经开始了。虽然当时仍然有许多亮眼的成就，像是阿里在9月发布的Qwen2.5 Instruct 72B，在海外研究机构的评分中也超过了GPT 4.0和Anthropic的Claude Sonnet，OpenAI同时期发布的推理模型o1预览版。虽然推理成本在下降，但是相比于4O，输入价格还是贵了3倍，输出价格贵了4倍，满血的Pro版要200美元一个月。

国内的大模型玩家开始转向推理范式，继续追赶OpenAI，但是投资人和消费者却渐渐失去了兴趣。面对动辄数十亿单位的融资规模，投资人开始变得格外在意大模型企业用户增长和直接挣钱的能力，而消费者也对大模型排名“刷榜”的行为感到越来越麻木，搞不清楚不同榜单的区别。

腾讯《深网》曾报道，2024年9月起，以Kimi为代表的大模型“六小龙们”有4家没有再收到数亿级的融资。虽然与AI相关的应用在消费端月活用户已经突破了1.2亿，但用户日均使用时长不到5分钟，大部分的App卸载率达到了20%。所谓的“AI赋能”不过是在原有的App里加了一个聊天对话框，一个搜索结果总结页面或是一个AI评论区机器人，难以称之为“革新”。多模态生成模型中，字节的即梦AI月活规模196万，阿里的妙鸭相机月活28万，但能影响世界的“杀手级应用”迟迟没有出现。

在B端，大模型企业的日子也不好过。根据非凡数据，2024年前三季度，智普公开了11个中标项目，平均每个项目中标金额只有200多万，有些甚至会低至90万。在前几名中只有智普是创业公司，拿单最多的玩家是中国电信。在政企订单领域，大厂和央企吃肉，明星创业公司能喝到多少汤呢？企业级API价格战已经卷到飞起，但定制化和卖传统to B企业服务没有本质区别。靠“一单一议”注定无法实现边际成本递减，不仅销售周期长，回款周期也长。以至于有人调侃，真正的AI四小龙是四家紧密跟踪报道AI行业的自媒体，毕竟这四家自媒体是真的赚到钱了。

AI模型不能让人兴奋，深层原因还是堆砌算力、参数和数据换取模型性能提升的边际效益正在持续衰减。为了优化计算资源，OpenAI甚至已经在计划明年生产资源芯片，为保证数据中心的能源供应，Sam Altman甚至要亲自下场创办公司建设核电站。3月初发布的GPT 4.5被评价“能力一般，欲望不小”，输入价格是DeepSeek的1000多倍。Sam Altman为OpenAI没能同时推出Plus和Pro版找的理由是“GPU不够用了”。

为什么DeepSeek R1一出市就可以震撼世界？或许真正的原因不仅在于其低廉的成本和优异的性能，更在于它为“陷入瓶颈”的大模型训练重新找到一条新路。传统大模型训练依赖大量的监督数据和复杂流程，人工标注的监督微调数据不仅收集成本高昂，而且难以扩展。更为重要的是这类数据往往会带入人类先验的“偏见”，限制模型自主探索更优路径的能力。就好比是一个老师只会“填鸭式教育”，每道数学题都手把手教解题步骤，要求学生严格模仿板书答题。学生只会机械地套“解题模板”，一旦碰到变形题就会卡壳，一旦出现超纲题，正确率就更是暴跌。

而在DeepSeek R1的论文中，研究人员使用了强化学习（RL）的方式训练模型，不依赖人工标注的监督数据，成功激发出了模型自我验证、反思，长链条推理的能力让大模型不需要人工标注就可以实现能力的进化。DeepSeek的训练方法就好比是一个老师直接抛出没有教过的奥数题，只告诉学生评分的规则，而学生不断试错。写出错误的解法，再根据自己的得分，反推自己哪些步骤扣分，哪些步骤加分，最后自己发现了验算技巧，做错题反思解题策略，研究自己哪一个步骤还可以做得更好。

传统大模型训练认为，如果不先教例题，学生就不可能学会解题。但DeepSeek R1证明了停止填鸭式教育，让学生自己在实战中总结经验，反而能培养出真正的数学天才。在论文中，研究人员发现，DeepSeek在解决一道数学题时，模型在中间推导的时候突然意识到了原来解法可能会很复杂，主动中断了思路，重新评估解题步骤，回到起点，并重新选择了更高效的解法，还非常拟人地说了一句，“等等，我好像悟了”。

在强化学习训练的过程中，DeepSeek开始自我进化，学会了自我验证、反思，生成长链条推力的能力，甚至出现“顿悟时刻”，在解决问题卡壳的时候，自己调整解题方法。

不需要两万五千块英伟达A100，不需要一年两亿元电费，不需要人工标注的海量数据，不需要天价API，DeepSeek R1的成功被“献入了瓶颈”的大模型训练重新找到了一条“康庄大道”。而对所有人都更加意义重大的是DeepSeek是开源的，任何人都可以免费使用自己训练。

从2月24号到28号的开源周，DeepSeek一口气公布了5个代码库，构建了一套从软件层面重构硬件性能的算力系统，在不升级硬件的前提下，把训练效率直接提升了40%到60%。

这种透明搅乱了模型大混战的竞争逻辑，当模型参数、训练策略乃至商业应用接口都呈现在开源社区时，“闭源社区”用数据规模与硬件投入构筑的护城河就顿时荡然无存了。一个能力超强且便宜的开源模型成了技术底座，就像乐高造出了零部件，接入DeepSeek的构建这个生态的人，就像拼积木的乐高大师。

DeepSeek让大模型有了新的故事，也让AI产品的形态有了新的想象。现在DeepSeek把大模型带入到了一个类似“安卓时刻”的节点，便宜的价格给曾经需要频繁调用API成本居高不下的应用带来了盈利机会。蒸馏出的各种小参数版本对算力资源需求少，可以直接部署到端侧，也让人们开始期待更好用的AI笔记本、AI眼镜等智能硬件。

互联网大厂中，腾讯是最激烈的对DeepSeek生态做出反应的那一个。业内公认腾讯擅长做产品，比如微信竟然能在电商赛道找到一个差异化的突破点，就是在微信好友的对话框里加“送礼物”功能。腾讯元宝给原版DeepSeek提供增益价值，将微信公众号加入DeepSeek联网搜索信源，上线微信文件一键上传功能，融合混元的多模态能力，弥补了原版DeepSeek不能语音、图片输入的短板，延续了腾讯此前在移动互联网的角色：把产品带入千家万户。

给做无效PPT的年轻人省去自从微信下载文件再上传的繁琐步骤，给需要法律建议的中年人带来看懂合同的DeepSeek建议，给老年人一个用语音即可交互的聪明、稳定的聊天搭子。

腾讯元宝在国区苹果商店面下载榜登顶第一，充分说明了AI时代在场景中做产品仍然是不变的法则。